{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CUDA_VISIBLE_DEVICES=X python train.py --cuda --outpath ./outputs\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from net import NetS, NetC\n",
    "from LoadData import Dataset, loader, Dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = '../stage1_train/'\n",
    "TEST_PATH = '../stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 670/670 [02:00<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:51: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  out_of_range_float = (np.issubdtype(image.dtype, np.float) and\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-894edc83e3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m#Y=np.rollaxis(Y_train, 3, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m#X.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(arr, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imshow'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(im, ax, show_cbar, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0max_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcmap\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_default_colormap\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshow_cbar\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mshow_cbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mdivider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_axes_locatable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1890\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1891\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5116\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5118\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5119\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    547\u001b[0m         if (self._A.ndim not in (2, 3) or\n\u001b[1;32m    548\u001b[0m                 (self._A.ndim == 3 and self._A.shape[-1] not in (3, 4))):\n\u001b[0;32m--> 549\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    }
   ],
   "source": [
    "X=np.rollaxis(X_train, 3, 1)\n",
    "Y=np.rollaxis(Y_train, 3, 1)\n",
    "X.shape\n",
    "#imshow(X[10])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 3, 128, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in x_train]) # transform to torch tensors\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in y_train])\n",
    "train_dataset = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    " # create your dataloader\n",
    "\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in x_val]) # transform to torch tensors\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in y_val])\n",
    "val_dataset = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([36, 128, 128, 3])\n",
      "torch.Size([32, 128, 128, 3])\n",
      "torch.Size([32, 128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader, 1):\n",
    "    #train C\n",
    "    NetC.zero_grad()\n",
    "    input, label = Variable(data[0]), Variable(data[1])\n",
    "     \n",
    "    print(input.shape)\n",
    "    input = input.cuda()\n",
    "    print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "batchSize=36\n",
    "niter=10000 #number of epochs to train for\n",
    "lr=0.0002 #'Learning Rate. Default=0.02'\n",
    "ngpu=1 #number of GPUs to use, for now it only supports one GPU\n",
    "beta1=0.5  #beta1 for adam. default=0.5\n",
    "decay=0.5 #Learning rate decay. default=0.5\n",
    "#parser.add_argument('--cuda', action='store_true', help='using GPU or not')\n",
    "seed=666 #random seed to use. Default=1111\n",
    "outpath='./outputs' #folder to output images and model checkpoints\n",
    "cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(outpath)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e727ab36b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom weights initialization called on NetS and NetC\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "def dice_loss(input,target):\n",
    "    num=input*target\n",
    "    num=torch.sum(num,dim=2)\n",
    "    num=torch.sum(num,dim=2)\n",
    "\n",
    "    den1=input*input\n",
    "    den1=torch.sum(den1,dim=2)\n",
    "    den1=torch.sum(den1,dim=2)\n",
    "\n",
    "    den2=target*target\n",
    "    den2=torch.sum(den2,dim=2)\n",
    "    den2=torch.sum(den2,dim=2)\n",
    "\n",
    "    dice=2*(num/(den1+den2))\n",
    "\n",
    "    dice_total=1-1*torch.sum(dice)/dice.size(0)#divide by batchsize\n",
    "\n",
    "    return dice_total\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n",
      "NetS(\n",
      "  (convblock1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock1_1): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): LeakyReLU(0.2, inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): LeakyReLU(0.2, inplace)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock2_1): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): LeakyReLU(0.2, inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): LeakyReLU(0.2, inplace)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock3_1): ResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): LeakyReLU(0.2, inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): LeakyReLU(0.2, inplace)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock4_1): ResidualBlock(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): LeakyReLU(0.2, inplace)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): LeakyReLU(0.2, inplace)\n",
      "    (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock5_1): ResidualBlock(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): LeakyReLU(0.2, inplace)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): LeakyReLU(0.2, inplace)\n",
      "    (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock6): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock6_1): Sequential(\n",
      "    (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock7): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock8): Sequential(\n",
      "    (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (deconvblock1): Sequential(\n",
      "    (0): ConvTranspose2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock2): Sequential(\n",
      "    (0): Conv2d(4096, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock2_1): Sequential(\n",
      "    (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock3): Sequential(\n",
      "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock3_1): ResidualBlock_D(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock4): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(1024, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3.0, 0))\n",
      "      (conv_l2): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3.0))\n",
      "      (conv_r1): Conv2d(1024, 512, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3.0))\n",
      "      (conv_r2): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), padding=(3.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock4_1): ResidualBlock_D(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock5): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(1024, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3.0, 0))\n",
      "      (conv_l2): Conv2d(256, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3.0))\n",
      "      (conv_r1): Conv2d(1024, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3.0))\n",
      "      (conv_r2): Conv2d(256, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock5_1): ResidualBlock_D(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock6): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(512, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4.0, 0))\n",
      "      (conv_l2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4.0))\n",
      "      (conv_r1): Conv2d(512, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4.0))\n",
      "      (conv_r2): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock6_1): ResidualBlock_D(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock7): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(256, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4.0, 0))\n",
      "      (conv_l2): Conv2d(64, 64, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4.0))\n",
      "      (conv_r1): Conv2d(256, 64, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4.0))\n",
      "      (conv_r2): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock7_1): ResidualBlock_D(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock8): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(128, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5.0, 0))\n",
      "      (conv_l2): Conv2d(64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5.0))\n",
      "      (conv_r1): Conv2d(128, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5.0))\n",
      "      (conv_r2): Conv2d(64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock8_1): ResidualBlock_D(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu3): ReLU(inplace)\n",
      "  )\n",
      "  (deconvblock9): Sequential(\n",
      "    (0): Conv2d(64, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  )\n",
      ")\n",
      "NetC(\n",
      "  (convblock1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock1_1): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(64, 128, kernel_size=(13, 1), stride=(1, 1), padding=(6.0, 0))\n",
      "      (conv_l2): Conv2d(128, 128, kernel_size=(1, 13), stride=(1, 1), padding=(0, 6.0))\n",
      "      (conv_r1): Conv2d(64, 128, kernel_size=(1, 13), stride=(1, 1), padding=(0, 6.0))\n",
      "      (conv_r2): Conv2d(128, 128, kernel_size=(13, 1), stride=(1, 1), padding=(6.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock2_1): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(128, 256, kernel_size=(11, 1), stride=(1, 1), padding=(5.0, 0))\n",
      "      (conv_l2): Conv2d(256, 256, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5.0))\n",
      "      (conv_r1): Conv2d(128, 256, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5.0))\n",
      "      (conv_r2): Conv2d(256, 256, kernel_size=(11, 1), stride=(1, 1), padding=(5.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock3_1): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(256, 512, kernel_size=(9, 1), stride=(1, 1), padding=(4.0, 0))\n",
      "      (conv_l2): Conv2d(512, 512, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4.0))\n",
      "      (conv_r1): Conv2d(256, 512, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4.0))\n",
      "      (conv_r2): Conv2d(512, 512, kernel_size=(9, 1), stride=(1, 1), padding=(4.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock4_1): Sequential(\n",
      "    (0): GlobalConvBlock(\n",
      "      (conv_l1): Conv2d(512, 1024, kernel_size=(7, 1), stride=(1, 1), padding=(3.0, 0))\n",
      "      (conv_l2): Conv2d(1024, 1024, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3.0))\n",
      "      (conv_r1): Conv2d(512, 1024, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3.0))\n",
      "      (conv_r2): Conv2d(1024, 1024, kernel_size=(7, 1), stride=(1, 1), padding=(3.0, 0))\n",
      "    )\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock5_1): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      "  (convblock6): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:116: UserWarning: \n",
      "    Found GPU0 GeForce GTX 950M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "print('===> Building model')\n",
    "NetS = NetS(ngpu = ngpu)\n",
    "# NetS.apply(weights_init)\n",
    "print(NetS)\n",
    "NetC = NetC(ngpu = ngpu)\n",
    "# NetC.apply(weights_init)\n",
    "print(NetC)\n",
    "NetS = NetS.cuda()\n",
    "NetC = NetC.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "optimizerG = optim.Adam(NetS.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerD = optim.Adam(NetC.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# load training data\n",
    "\n",
    "dataloader =utils.DataLoader(train_dataset,batchSize)\n",
    "# load testing data\n",
    "dataloader_val= utils.DataLoader(val_dataset,10) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 3, 128, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (48) : no kernel image is available for execution on the device at c:\\anaconda2\\conda-bld\\pytorch_1519501749874\\work\\torch\\lib\\thcunn\\generic/LeakyReLU.cu:29",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e9e83540e204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[1;31m#output = F.sigmoid(output*k)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Desktop\\Sem 2\\Visual Recogin\\Project\\SegAN\\net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[1;31m# for now it only supports one GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngpu\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mencoder1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvblock1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mencoder1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvblock1_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mencoder2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvblock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Davin\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (48) : no kernel image is available for execution on the device at c:\\anaconda2\\conda-bld\\pytorch_1519501749874\\work\\torch\\lib\\thcunn\\generic/LeakyReLU.cu:29"
     ]
    }
   ],
   "source": [
    "max_iou = 0\n",
    "NetS.train()\n",
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 1):\n",
    "        #train C\n",
    "        NetC.zero_grad()\n",
    "        input, label = Variable(data[0]), Variable(data[1])\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target = label.cuda()\n",
    "        target = target.type(torch.FloatTensor)\n",
    "        target = target.cuda()\n",
    "        print(input.shape)\n",
    "        output = NetS(input)\n",
    "        #output = F.sigmoid(output*k)\n",
    "        output = F.sigmoid(output)\n",
    "        output = output.detach()\n",
    "        output_masked = input.clone()\n",
    "        input_mask = input.clone()\n",
    "        #detach G from the network\n",
    "        for d in range(3):\n",
    "            output_masked[:,d,:,:] = input_mask[:,d,:,:].unsqueeze(1) * output\n",
    "        if cuda:\n",
    "            output_masked = output_masked.cuda()\n",
    "        result = NetC(output_masked)\n",
    "        target_masked = input.clone()\n",
    "        for d in range(3):\n",
    "            target_masked[:,d,:,:] = input_mask[:,d,:,:].unsqueeze(1) * target\n",
    "        if cuda:\n",
    "            target_masked = target_masked.cuda()\n",
    "        target_D = NetC(target_masked)\n",
    "        loss_D = - torch.mean(torch.abs(result - target_D))\n",
    "        loss_D.backward()\n",
    "        optimizerD.step()\n",
    "        #clip parameters in D\n",
    "        for p in NetC.parameters():\n",
    "            p.data.clamp_(-0.05, 0.05)\n",
    "        #train G\n",
    "        NetS.zero_grad()\n",
    "        output = NetS(input)\n",
    "        output = F.sigmoid(output)\n",
    "\n",
    "        for d in range(3):\n",
    "            output_masked[:,d,:,:] = input_mask[:,d,:,:].unsqueeze(1) * output\n",
    "        if cuda:\n",
    "            output_masked = output_masked.cuda()\n",
    "        result = NetC(output_masked)\n",
    "        for d in range(3):\n",
    "            target_masked[:,d,:,:] = input_mask[:,d,:,:].unsqueeze(1) * target\n",
    "        if cuda:\n",
    "            target_masked = target_masked.cuda()\n",
    "        target_G = NetC(target_masked)\n",
    "        loss_dice = dice_loss(output,target)\n",
    "        loss_G = torch.mean(torch.abs(result - target_G))\n",
    "        loss_G_joint = torch.mean(torch.abs(result - target_G)) + loss_dice\n",
    "        loss_G_joint.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "    print(\"===> Epoch[{}]({}/{}): Batch Dice: {:.4f}\".format(epoch, i, len(dataloader), 1 - loss_dice.data[0]))\n",
    "    print(\"===> Epoch[{}]({}/{}): G_Loss: {:.4f}\".format(epoch, i, len(dataloader), loss_G.data[0]))\n",
    "    print(\"===> Epoch[{}]({}/{}): D_Loss: {:.4f}\".format(epoch, i, len(dataloader), loss_D.data[0]))\n",
    "    vutils.save_image(data[0],\n",
    "            '%s/input.png' % outpath,\n",
    "            normalize=True)\n",
    "    vutils.save_image(data[1],\n",
    "            '%s/label.png' % outpath,\n",
    "            normalize=True)\n",
    "    vutils.save_image(output.data,\n",
    "            '%s/result.png' % outpath,\n",
    "            normalize=True)\n",
    "    if epoch % 10 == 0:\n",
    "        NetS.eval()\n",
    "        IoUs, dices = [], []\n",
    "        for i, data in enumerate(dataloader_val, 1):\n",
    "            input, gt = Variable(data[0]), Variable(data[1])\n",
    "            if cuda:\n",
    "                input = input.cuda()\n",
    "                gt = gt.cuda()\n",
    "            pred = NetS(input)\n",
    "            pred[pred < 0.5] = 0\n",
    "            pred[pred >= 0.5] = 1\n",
    "            pred = pred.type(torch.LongTensor)\n",
    "            pred_np = pred.data.cpu().numpy()\n",
    "            gt = gt.data.cpu().numpy()\n",
    "            for x in range(input.size()[0]):\n",
    "                IoU = np.sum(pred_np[x][gt[x]==1]) / float(np.sum(pred_np[x]) + np.sum(gt[x]) - np.sum(pred_np[x][gt[x]==1]))\n",
    "                dice = np.sum(pred_np[x][gt[x]==1])*2 / float(np.sum(pred_np[x]) + np.sum(gt[x]))\n",
    "                IoUs.append(IoU)\n",
    "                dices.append(dice)\n",
    "\n",
    "        NetS.train()\n",
    "        IoUs = np.array(IoUs, dtype=np.float64)\n",
    "        dices = np.array(dices, dtype=np.float64)\n",
    "        mIoU = np.mean(IoUs, axis=0)\n",
    "        mdice = np.mean(dices, axis=0)\n",
    "        print('mIoU: {:.4f}'.format(mIoU))\n",
    "        print('Dice: {:.4f}'.format(mdice))\n",
    "        if mIoU > max_iou:\n",
    "            max_iou = mIoU\n",
    "            torch.save(NetS.state_dict(), '%s/NetS_epoch_%d.pth' % (outpath, epoch))\n",
    "        vutils.save_image(data[0],\n",
    "                '%s/input_val.png' % outpath,\n",
    "                normalize=True)\n",
    "        vutils.save_image(data[1],\n",
    "                '%s/label_val.png' % outpath,\n",
    "                normalize=True)\n",
    "        pred = pred.type(torch.FloatTensor)\n",
    "        vutils.save_image(pred.data,\n",
    "                '%s/result_val.png' % outpath,\n",
    "                normalize=True)\n",
    "    if epoch % 25 == 0:\n",
    "        lr = lr*decay\n",
    "        if lr <= 0.00000001:\n",
    "            lr = 0.00000001\n",
    "        print('Learning Rate: {:.6f}'.format(lr))\n",
    "        # print('K: {:.4f}'.format(k))\n",
    "        print('Max mIoU: {:.4f}'.format(max_iou))\n",
    "        optimizerG = optim.Adam(NetS.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        optimizerD = optim.Adam(NetC.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
